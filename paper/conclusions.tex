\section{Conclusions and future directions}

This project successfully demonstrated that large-scale explorations of a space of mathematical statements---in this case, the implications or non-implications between selected equational laws---can be crowdsourced using modern collaboration platforms and proof assistants.  No single tool or method was able to study the entirety of this space, and many informal proofs generated contained non-trivial errors; but there were multiple techniques that could treat significant portions of the space, and through a collaborative effort combined with the proof validation provided by \emph{Lean}, one could synthesize these partial and fallible contributions into a complete and validated description of the entire implication graph.  While this particular graph was a comparatively simple structure to analyze, we believe that this paradigm could also serve as a model for future projects devoted to exploring more sophisticated large-scale mathematical structures.

Several factors appeared to be helpful in ensuring the success of the project, including the following:
\begin{itemize}
\item \textbf{A clearly stated primary goal, with an end condition and precise numerical metrics to measure partial completion.}  From the outset, there was a specific goal to attain, namely to completely determine and then formalize the implication graph on the original set of $4694$ laws.  Progress towards that goal could be measured by a number of metrics, such as the number of implications that were conjectured but unformalized, or not conjectured at all.   Such metrics allowed participants to see how partial contributions, such as formalizing a certain subset of implications, advanced the project directly towards its primary goal.  This is not to say that all activity was devoted solely towards this primary goal, but it did provide a coherent focus to help guide and motivate other secondary activities.
\item \textbf{A highly modular project}.  It was possible for any given coauthor to work on a small subset of implications and focus on a single proof technique, without needing to understand or rely upon other contributions to the project.  This allowed the work to be both parallelized and decentralized; many contributors launched their own investigations broadly within the framework of the project, without needing centralized approval or coordination.
\item \textbf{Low levels of required mathematical and formal prerequisites}.  The problems considered in the project did not require advanced mathematical knowledge (beyond a general familiarity with abstract algebra), nor a sophisticated understanding of formal proof assistants.  This permitted contributions from a broad spectrum of participants, including those without a graduate mathematical training, as well as mathematicians with no experience in proof formalization.  At a technical level, it also meant that formalization of proofs into \emph{Lean} could be done immediately once certain base definitions (such as \texttt{Magma}) were constructed.  This can be compared for instance with the recent formalization of the Polynomial Freiman--Ruzsa conjecture\footnote{\url{https://github.com/teorth/pfr}}, in which significant effort was expended in the first few days to settle on a suitable framework to formalize the mathematics of Shannon entropy.  While some more sophisticated formal structures (such as the syntactic description of laws as pairs of words in a \texttt{FreeMagma}) were later introduced in the project, it was relatively straightforward to refactor previously written code to be compatible with these structures as they were incorporated into the project.
\item \textbf{Variable levels of difficulty, and the amenability to partial progress.}  Traditional mathematics projects generally involve a small number of extremely hard problems, with incomplete progress on these problems being difficult to convert into clean partial results.  In contrast, the ETP studied a large number of problems with a very broad range of difficulty, so that even if a given proof strategy did not work for a given implication, it could be the case that there was some class of easier implications for which the strategy was successful.  This allowed for a means to validate such ideas, and allowed the project to build up a useful and diverse toolbox of proof techniques which became increasingly necessary to handle the final and most difficult implications in the project.  It also created a dynamic in which the project initially focused on easy techniques to resolve a significant fraction of the implications, gradually transitioning into more sophisticated methods that focused on a much smaller number of outstanding implications that had proven resistant (or even ``immune'') to all easier approaches.
\item \textbf{Centralized and standardized platforms for discussion, project management, and validation.}  While the project was decentralized at the level of the participant, there was a centralized location (a channel\footnote{\url{https://leanprover.zulipchat.com/\#narrow/channel/458659-Equational}} on the Lean Zulip) to discuss all aspects of the project, as well as a centralized repository\footnote{\url{https://github.com/teorth/equational_theories}} to track all contributions and outstanding issues, a centralized blueprint\footnote{\url{https://teorth.github.io/equational_theories/blueprint/}} to describe technical details of proofs to be formalized, and a single formal language (\emph{Lean}) to validate all contributions. A significant portion of the activity in the early stages of the project was devoted to setting out the standards and workflows for handling both the discussion and the contributions, in particular setting up a contributions page\footnote{\url{https://github.com/teorth/equational_theories/blob/main/CONTRIBUTING.md}} and adopting a code of conduct\footnote{\url{https://github.com/teorth/equational_theories/blob/main/CODE_OF_CONDUCT.md}}.  This gave some structure and predictability to what might otherwise be a chaotic effort.
\item \textbf{Development of custom visualization tools.}  As discussed in \Cref{sec:gui-sec}, several tools were developed (in part with AI assistance) to help visualize and navigate the implication graph while it was in a partial stage of development, allowing for participants to independently identify problems to work on, and to validate and use the contributions of other participants even before they were fully formalized.  For instance, a participant could propose a finite counterexample to an implication by posting a link to the magma in \emph{Finite Magma Explorer}, allowing for immediate validation of the counterexample, or use \emph{Equation Explorer} or \emph{Graphiti} to observe some interesting phenomenon in the implication graph that other participants could reproduce and study.
\item \textbf{Applicability of existing software tools.}  As described in \Cref{automated-sec}, many of the implications in the ETP were amenable to application of ``off-the-shelf'' automated theorem provers (ATPs); while some trial and error was needed to determine good choices of parameters, these tools could largely be applied directly to the project without extensive customization.  (However, the later transcription of ATP output into Lean was sometimes non-trivial.)
\item \textbf{Receptiveness to new techniques and tools.}  Crucially, the methods used to make progress on the project were not specified in advance, and contributions from participants with new ideas, techniques, or software tools that were not initially anticipated were welcomed.  For instance, the theory of canonizers (\Cref{canon-sec}) was not initially known to the first project participants, but was brought to the attention of the project by a later contributor.  Conversely, while there were hopes expressed early in the project that modern large language models (LLMs) could automatically generate many of the proofs required, it turned out in practice that other forms of automation, particularly ATPs, were significantly more effective at this task (at least if one restricted to publicly available LLMs), and the project largely moved away from the use of such LLMs (other than to help create the code for the visualization tools).
\end{itemize}

There are several mathematical and computational questions that could potentially be addressed in future work building upon the outcomes of ETP.  Here is a list of some possible such future directions.
\begin{enumerate}
  \item Does the law $\x \formaleq \y \op (\x \op ((\y \op \x) \op \y))$ \eqref{eq677} imply $\x \formaleq ((\x \op \x) \op \x) \op \x$ \eqref{eq255} for finite magmas? This is the last remaining implication (up to duality) for finite magmas to be resolved.  A number of partial results on this problem may be found at \url{https://teorth.github.io/equational_theories/blueprint/677-chapter.html}.
  \item Does the law $\x \formaleq \y \op (\y \op (\y \op (\x \op (\z \op \y))))$ \eqref{eq5093} have any infinite models? In \cite{Kisielewicz2} it was shown that it has no finite models, but the infinite model case was left as an open question.
  \item The ETP focused on determining relations $\E \models \E'$ between one law and another.  Could the same methods also systematically determine more complex logical relations, such as $\E_1 \wedge \E_2 \models \E_3$, for all laws $\E_1,\E_2,\E_3$ in a specified set?
  \item A key feature of finite magmas $\Magma$ is that they are surjunctive, in the sense that any definable map from $M$ to itself that is surjective, is also injective (or vice versa), where ``definable'' is with respect to the language of magmas.  Are there equational theories that admit surjunctive models, but yet do not have any finite models?
  \item Are there interesting examples of implications $\E_1 \models \E_2$ which are ``irreducible'' in the sense that there is no equational law $\E$ with $\E_1 \models \E \models \E_2$, other than those laws equivalent to either $\E_1$ or $\E_2$?
  \item How ``stable'' is a given law $\E$?  For instance, if a finite magma satisfies a law $\E$ some proportion $1-\eps$ of the time, with $\eps$ small, can the magma be perturbed into one that satisfies $\E$ exactly?  Related to this is the question of whether a law $\E$ is ``rigid'' or ``mutable'': is it possible to make a small number of modifications to a magma satisfying $\E$ in a way that still preserves $\E$?  Such properties helped suggest whether certain magma construction techniques, such as modifying a base magma, were likely to be successful.
\end{enumerate}

\subsection{Miscellaneous remarks}

It is possible that the timing in which certain proof methods were introduced into the project created some opportunity costs.  For instance, by deploying automated theorem provers at an early stage, we might have settled some implications that had more interesting human-readable proofs that we missed.  Similarly, we developed some sophisticated theory for the equation $\Eq{854}$, such as \Cref{unique-factorization}, that is now superseded by finite counterexamples; but had the finite counterexamples been discovered first, we would not have found the theoretical arguments.  It may be productive for future work to revisit some portions of the implication graph and locate alternate proofs and methods.


\section*{Acknowledgments}

We are grateful to the many additional participants to the Equational Theories Project for their
numerous comments and encouragement, with particular thanks to  Stanley Burris, Edward van de Meent and David Roberts.
